# Speed Layer Silver Ingestion - Restored

## âš ï¸ Issue Identified

During code cleanup, I mistakenly removed `src/speed/hourly_silver_ingestion.py` which contains critical functions used by the `speed_layer_silver_ingestion` DAG.

## âœ… Resolution

Restored `src/speed/hourly_silver_ingestion.py` with all required functions:

### Functions Provided:

1. **`check_flight_tracker_health()`**
   - Verifies flight-tracker service is running
   - Reports accumulated flight count
   - Checks WebSocket connections
   - Pushes metrics to XCom

2. **`fetch_accumulated_data()`**
   - Fetches enriched flight data from flight-tracker API
   - Requires API key authentication
   - Pushes flight data to XCom for downstream tasks
   - Handles empty data gracefully

3. **`persist_to_silver()`**
   - Creates Spark session with S3A configuration
   - Reads flight data from XCom
   - Writes partitioned Parquet files to MinIO
   - Path: `s3a://aviation-silver/speed_layer/year=YYYY/month=MM/day=DD/hour=HH`
   - Adds processing metadata (processing_time, source)

4. **`clear_accumulator()`**
   - Clears flight-tracker accumulator after successful persistence
   - Only clears if data was actually persisted
   - Non-critical operation (doesn't raise on failure)

5. **`print_summary()`**
   - Prints pipeline execution summary
   - Reports flights processed and execution time
   - Uses trigger_rule='all_done' to always execute

## ğŸ“Š DAG Configuration

```yaml
DAG ID: speed_layer_silver_ingestion
Schedule: 0 * * * * (hourly, at minute 0)
Owner: aviation-team
Retries: 2
Retry Delay: 2 minutes
Timeout: 30 minutes
Max Active Runs: 1
```

## ğŸ”„ Pipeline Flow

```
check_health â†’ fetch_data â†’ persist_silver â†’ clear_state â†’ summary
```

### Task Dependencies:
- **Health check must pass** before fetching data
- **Data fetch must succeed** before persistence
- **Persistence must complete** before clearing accumulator
- **Summary always runs** (trigger_rule='all_done')

## ğŸ—‚ï¸ Silver Layer Structure

```
s3a://aviation-silver/
â””â”€â”€ speed_layer/
    â””â”€â”€ year=2026/
        â””â”€â”€ month=01/
            â””â”€â”€ day=04/
                â””â”€â”€ hour=10/
                    â”œâ”€â”€ part-00000.parquet
                    â”œâ”€â”€ part-00001.parquet
                    â””â”€â”€ ...
```

## ğŸ“‹ Schema (36 fields)

### Core Fields:
- icao24, callsign, origin_country
- time_position, last_contact, ingestion_time

### Position & Dynamics:
- longitude, latitude, baro_altitude, geo_altitude
- velocity, true_track, vertical_rate, on_ground

### Enriched Fields (from Spark):
- airline_prefix, flight_number, airline_name, airline_iata, airline_icao
- origin_code, origin_city, origin_airport, origin_lat, origin_lon
- destination_code, destination_city, destination_airport, destination_lat, destination_lon

### Accumulator Tracking:
- first_seen, last_seen, position_count

### Processing Metadata:
- processing_time, source

## âœ… Verification

```bash
# 1. Check imports work
docker exec airflow-webserver python -c \
  'from src.speed.hourly_silver_ingestion import check_flight_tracker_health, 
   fetch_accumulated_data, persist_to_silver, clear_accumulator, print_summary'

# 2. Validate DAG syntax
docker exec airflow-webserver python dags/speed_layer_silver_ingestion.py

# 3. Check DAG is registered
docker exec airflow-webserver airflow dags list | grep speed_layer

# 4. Manually trigger DAG
docker exec airflow-webserver airflow dags trigger speed_layer_silver_ingestion
```

## ğŸ¯ Testing the Pipeline

### 1. Wait for Accumulator to Fill
```bash
# Check current count
curl http://localhost:8050/api/flights | jq '.count'
# Should show 300+ flights after ~15 minutes
```

### 2. Manually Trigger DAG
```bash
docker exec airflow-webserver airflow dags trigger speed_layer_silver_ingestion
```

### 3. Monitor Execution
- Open Airflow UI: http://localhost:8080
- Navigate to DAGs â†’ speed_layer_silver_ingestion
- Watch task progress in Graph view

### 4. Verify Silver Data
```bash
# Check MinIO
mc ls minio/aviation-silver/speed_layer/

# Or use Airflow logs to see the output path
docker exec airflow-scheduler airflow tasks logs speed_layer_silver_ingestion persist_to_silver <execution_date>
```

## ğŸš¨ Error Handling

### Empty Accumulator:
- fetch_data returns empty list
- persist_silver skips processing
- clear_accumulator skips clearing
- Summary reports 0 flights processed

### API Failures:
- Health check fails â†’ Pipeline stops
- Fetch data fails â†’ Pipeline stops (retries 2 times)
- Persist fails â†’ Pipeline stops (accumulator NOT cleared)
- Clear fails â†’ Logged but doesn't fail pipeline

### Spark Failures:
- Configuration errors â†’ Check MinIO connectivity
- Schema errors â†’ Check flight data structure matches schema
- Write errors â†’ Check MinIO bucket exists and is writable

## ğŸ“ File Status

- âœ… `src/speed/hourly_silver_ingestion.py` - **Restored** (304 lines)
- âœ… `dags/speed_layer_silver_ingestion.py` - **Working** (DAG registered)
- âœ… All imports validated
- âœ… DAG syntax validated
- âœ… Functions tested in Airflow container

## ğŸ”® Next Steps

1. **Wait 1 hour** for automatic execution at top of hour
2. **Or trigger manually** for immediate testing
3. **Monitor logs** for any issues
4. **Verify Silver layer data** in MinIO
5. **Check accumulator clears** after persistence

---

**Status**: âœ… Fully Operational  
**Date**: January 4, 2026  
**File Restored**: hourly_silver_ingestion.py (304 lines)
