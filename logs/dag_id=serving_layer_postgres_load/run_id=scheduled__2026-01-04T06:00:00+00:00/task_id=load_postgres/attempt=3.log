[2026-01-04T12:14:12.718+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2026-01-04T12:14:12.810+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: serving_layer_postgres_load.load_postgres scheduled__2026-01-04T06:00:00+00:00 [queued]>
[2026-01-04T12:14:12.832+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: serving_layer_postgres_load.load_postgres scheduled__2026-01-04T06:00:00+00:00 [queued]>
[2026-01-04T12:14:12.833+0000] {taskinstance.py:2303} INFO - Starting attempt 3 of 3
[2026-01-04T12:14:12.865+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): load_postgres> on 2026-01-04 06:00:00+00:00
[2026-01-04T12:14:12.882+0000] {standard_task_runner.py:63} INFO - Started process 207 to run task
[2026-01-04T12:14:12.896+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'serving_layer_postgres_load', 'load_postgres', 'scheduled__2026-01-04T06:00:00+00:00', '--job-id', '366', '--raw', '--subdir', 'DAGS_FOLDER/serving_layer_postgres_load.py', '--cfg-path', '/tmp/tmpgdt52tgf']
[2026-01-04T12:14:12.900+0000] {standard_task_runner.py:91} INFO - Job 366: Subtask load_postgres
[2026-01-04T12:14:13.065+0000] {task_command.py:426} INFO - Running <TaskInstance: serving_layer_postgres_load.load_postgres scheduled__2026-01-04T06:00:00+00:00 [running]> on host fbea5e1fe7fb
[2026-01-04T12:14:13.494+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='aviation' AIRFLOW_CTX_DAG_ID='serving_layer_postgres_load' AIRFLOW_CTX_TASK_ID='load_postgres' AIRFLOW_CTX_EXECUTION_DATE='2026-01-04T06:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2026-01-04T06:00:00+00:00'
[2026-01-04T12:14:13.497+0000] {taskinstance.py:430} INFO - ::endgroup::
[2026-01-04T12:14:13.567+0000] {logging_mixin.py:188} INFO - ============================================================
[2026-01-04T12:14:13.567+0000] {logging_mixin.py:188} INFO - RUNNING INCREMENTAL LOAD (only new files)
[2026-01-04T12:14:13.568+0000] {logging_mixin.py:188} INFO - ============================================================
[2026-01-04T12:14:13.569+0000] {logging_mixin.py:188} INFO - ============================================================
[2026-01-04T12:14:13.572+0000] {logging_mixin.py:188} INFO - AVIATION SERVING LAYER - INCREMENTAL LOAD
[2026-01-04T12:14:13.572+0000] {logging_mixin.py:188} INFO - ============================================================
[2026-01-04T12:14:13.604+0000] {logging_mixin.py:188} INFO - ✓ Database exists: aviation_db
[2026-01-04T12:14:13.644+0000] {logging_mixin.py:188} INFO - ✓ Tracking table ready: processed_files
[2026-01-04T12:14:13.645+0000] {logging_mixin.py:188} INFO - ✓ Flight states table ready: flight_states
[2026-01-04T12:14:13.669+0000] {logging_mixin.py:188} INFO -   Already processed: 22 files
[2026-01-04T12:16:40.348+0000] {logging_mixin.py:188} INFO - 
1. Checking for new data in Silver layer...
[2026-01-04T12:16:40.349+0000] {logging_mixin.py:188} INFO -   Reading batch data from: s3a://aviation-silver/enriched_states
[2026-01-04T12:16:42.094+0000] {logging_mixin.py:188} INFO -   No new files to process in batch
[2026-01-04T12:16:42.095+0000] {logging_mixin.py:188} INFO -   Reading speed data from: s3a://aviation-silver/speed_layer/enriched_flight_states
[2026-01-04T12:16:42.328+0000] {logging_mixin.py:188} INFO -   Found 4 new files (out of 8 total)
[2026-01-04T12:16:47.020+0000] {logging_mixin.py:188} INFO - 
2. Merging new data...
[2026-01-04T12:16:47.021+0000] {logging_mixin.py:188} INFO -   Normalizing speed layer data...
[2026-01-04T12:16:48.059+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2026-01-04T12:16:48.060+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/serving_layer_postgres_load.py", line 65, in load_postgres_task
    incremental_load()
  File "/opt/airflow/src/serving/postgres_loader.py", line 795, in incremental_load
    merged_df = merge_dataframes(batch_df, speed_df)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/serving/postgres_loader.py", line 512, in merge_dataframes
    normalized_speed = normalize_speed_data(speed_df)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/src/serving/postgres_loader.py", line 441, in normalize_speed_data
    return df.select(
           ^^^^^^^^^^
  File "/opt/spark/python/pyspark/sql/dataframe.py", line 3227, in select
    jdf = self._jdf.select(self._jcols(*cols))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/opt/spark/python/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `year` cannot be resolved. Did you mean one of the following? [`spi`, `icao24`, `sensors`, `squawk`, `callsign`].;
'Project [icao24#0, callsign#1, speed AS data_source#111, time_position#3L AS timestamp#112L, last_contact#4L, time_position#3L, latitude#7, longitude#6, baro_altitude#8, geo_altitude#9, on_ground#10, velocity#11, true_track#12, vertical_rate#13, squawk#14, spi#15, position_source#16, origin_code#23, origin_city#24, destination_code#28, destination_city#29, cast(null as string) AS route#113, cast(null as string) AS aircraft_model#114, cast(null as string) AS aircraft_type#115, ... 11 more fields]
+- Project [icao24#0, callsign#1, origin_country#2, time_position#3L, last_contact#4L, ingestion_time#5, longitude#6, latitude#7, baro_altitude#8, geo_altitude#9, on_ground#10, velocity#11, true_track#12, vertical_rate#13, squawk#14, spi#15, position_source#16, sensors#17, airline_prefix#18, airline_name#19, airline_iata#20, airline_icao#21, flight_number#22, origin_code#23, ... 13 more fields]
   +- Relation [icao24#0,callsign#1,origin_country#2,time_position#3L,last_contact#4L,ingestion_time#5,longitude#6,latitude#7,baro_altitude#8,geo_altitude#9,on_ground#10,velocity#11,true_track#12,vertical_rate#13,squawk#14,spi#15,position_source#16,sensors#17,airline_prefix#18,airline_name#19,airline_iata#20,airline_icao#21,flight_number#22,origin_code#23,... 12 more fields] parquet

[2026-01-04T12:16:48.127+0000] {taskinstance.py:1205} INFO - Marking task as FAILED. dag_id=serving_layer_postgres_load, task_id=load_postgres, execution_date=20260104T060000, start_date=20260104T121412, end_date=20260104T121648
[2026-01-04T12:16:48.181+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 366 for task load_postgres ([UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `year` cannot be resolved. Did you mean one of the following? [`spi`, `icao24`, `sensors`, `squawk`, `callsign`].;
'Project [icao24#0, callsign#1, speed AS data_source#111, time_position#3L AS timestamp#112L, last_contact#4L, time_position#3L, latitude#7, longitude#6, baro_altitude#8, geo_altitude#9, on_ground#10, velocity#11, true_track#12, vertical_rate#13, squawk#14, spi#15, position_source#16, origin_code#23, origin_city#24, destination_code#28, destination_city#29, cast(null as string) AS route#113, cast(null as string) AS aircraft_model#114, cast(null as string) AS aircraft_type#115, ... 11 more fields]
+- Project [icao24#0, callsign#1, origin_country#2, time_position#3L, last_contact#4L, ingestion_time#5, longitude#6, latitude#7, baro_altitude#8, geo_altitude#9, on_ground#10, velocity#11, true_track#12, vertical_rate#13, squawk#14, spi#15, position_source#16, sensors#17, airline_prefix#18, airline_name#19, airline_iata#20, airline_icao#21, flight_number#22, origin_code#23, ... 13 more fields]
   +- Relation [icao24#0,callsign#1,origin_country#2,time_position#3L,last_contact#4L,ingestion_time#5,longitude#6,latitude#7,baro_altitude#8,geo_altitude#9,on_ground#10,velocity#11,true_track#12,vertical_rate#13,squawk#14,spi#15,position_source#16,sensors#17,airline_prefix#18,airline_name#19,airline_iata#20,airline_icao#21,flight_number#22,origin_code#23,... 12 more fields] parquet
; 207)
[2026-01-04T12:16:48.268+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2026-01-04T12:16:48.327+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2026-01-04T12:16:48.329+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
