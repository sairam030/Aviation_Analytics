# Aviation Analytics Pipeline

Real-time and batch aviation data processing pipeline using Lambda Architecture with Apache Spark, Kafka, and PostgreSQL.

## ğŸš€ Features

- **Real-time Flight Tracking**: Live WebSocket-based flight map with 5-second updates
- **Batch Processing**: Historical flight data processing with Apache Spark
- **Analytics Tables**: 5 PostgreSQL tables with comprehensive flight analytics
- **Auto-restart Capability**: Spark streaming auto-restarts with wrapper scripts
- **S3-Compatible Storage**: MinIO for Bronze/Silver/Gold data lakes
- **Orchestration**: Apache Airflow for workflow management
- **Monitoring**: Spark UI, Kafka UI, and Airflow dashboards
- **Comprehensive Metrics**: Detailed pipeline execution metrics and logging
- **Task Tracking**: Per-task execution times, data volumes, and health checks

## Architecture

```
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                     DATA SOURCES                            â”‚
                                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
                                    â”‚  â”‚  OpenSky API    â”‚         â”‚  Historical     â”‚           â”‚
                                    â”‚  â”‚  (Real-time)    â”‚         â”‚  Parquet Files  â”‚           â”‚
                                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚                            â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                       â”‚      INGESTION LAYER       â”‚                       â”‚
                        â”‚                       â–¼                            â–¼                       â”‚
                        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                        â”‚              â”‚  Kafka Producer â”‚         â”‚  Airflow DAG    â”‚              â”‚
                        â”‚              â”‚  (15s interval) â”‚         â”‚  (Batch Load)   â”‚              â”‚
                        â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚     PROCESSING LAYER       â”‚                                       â”‚
        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                                       â”‚
        â”‚     â”‚         SPEED LAYER             â”‚                 â”‚          â”‚         BATCH LAYER                   â”‚
        â”‚     â”‚                                 â–¼                 â”‚          â”‚                                       â”‚
        â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚          â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
        â”‚     â”‚  â”‚    Kafka     â”‚â”€â”€â”€â–¶â”‚ Flight Tracker  â”‚         â”‚          â”‚    â”‚  Apache Spark   â”‚                â”‚
        â”‚     â”‚  â”‚   (Topic)    â”‚    â”‚ (Enrichment +   â”‚         â”‚          â”‚    â”‚  (ETL Jobs)     â”‚                â”‚
        â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  Accumulator)   â”‚         â”‚          â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
        â”‚     â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚          â”‚             â”‚                         â”‚
        â”‚     â”‚                               â”‚                  â”‚          â”‚             â–¼                         â”‚
        â”‚     â”‚                               â–¼                  â”‚          â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
        â”‚     â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚          â”‚    â”‚     MinIO       â”‚                â”‚
        â”‚     â”‚                      â”‚   WebSocket     â”‚         â”‚          â”‚    â”‚  Silver Layer   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚     â”‚                      â”‚   (Live Map)    â”‚         â”‚          â”‚    â”‚  (Enriched)     â”‚                â”‚
        â”‚     â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚          â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
        â”‚     â”‚                               â”‚                  â”‚          â”‚                                       â”‚
        â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚                                       â”‚
        â”‚                                     â”‚ (Hourly DAG)                â”‚                                       â”‚
        â”‚                                     â–¼                             â–¼                                       â”‚
        â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
        â”‚                            â”‚              MinIO Silver               â”‚                                    â”‚
        â”‚                            â”‚    (Batch + Speed Layer Merged)         â”‚                                    â”‚
        â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                    SERVING LAYER                                â”‚
                        â”‚                                â–¼                                â”‚
                        â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
                        â”‚                     â”‚   PostgreSQL    â”‚                         â”‚
                        â”‚                     â”‚  (Unified Data) â”‚                         â”‚
                        â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
                        â”‚                              â”‚                                  â”‚
                        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
                        â”‚              â–¼               â–¼               â–¼                  â”‚
                        â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
                        â”‚     â”‚   Metabase   â”‚ â”‚ Flight Map   â”‚ â”‚   Airflow    â”‚         â”‚
                        â”‚     â”‚  Dashboards  â”‚ â”‚  (Real-time) â”‚ â”‚   Web UI     â”‚         â”‚
                        â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Infrastructure

### Docker Services (15 containers)

| Service | Port | Description |
|---------|------|-------------|
| **Airflow Webserver** | 8080 | DAG management & monitoring |
| **Flight Tracker** | 8050 | Real-time flight map (FastAPI + WebSocket) |
| **Spark Master UI** | 8081 | Spark cluster monitoring |
| **Spark Worker 1** | 8082 | Worker node 1 (2 cores, 2GB RAM) |
| **Spark Worker 2** | 8083 | Worker node 2 (2 cores, 2GB RAM) |
| **Kafka UI** | 8084 | Kafka topics & consumers |
| **MinIO Console** | 9001 | Object storage (S3-compatible) |
| **Metabase** | 3000 | Analytics dashboards |
| **PostgreSQL** | 5432 | Analytics database |
| **Kafka** | 9092 | Message broker |
| **Zookeeper** | 2181 | Kafka coordination |
| **Airflow Scheduler** | - | Background task scheduler |
| **Airflow Triggerer** | - | Deferrable operator handler |
| **MinIO Storage** | 9000 | S3 API endpoint |

### Tech Stack

- **Apache Spark 3.5.1**: Distributed batch & streaming processing
- **Apache Kafka**: Real-time message streaming
- **Apache Airflow 2.10.4**: Workflow orchestration
- **PostgreSQL 13**: Analytics database
- **MinIO**: S3-compatible object storage
- **FastAPI**: Flight tracker backend
- **Python 3.11**: Core language

## ğŸ“Š Analytics Tables

The serving layer provides 5 comprehensive PostgreSQL tables:

### 1. **fact_flight_history**
Flight-level aggregations with 30+ metrics per flight:
- Flight duration, distance, speed statistics
- Altitude profile (min, max, avg)
- Position changes and trajectory metrics
- Airspace time distribution

### 2. **dim_route_analytics**
Route-level performance metrics:
- Average flight time per route
- Traffic frequency
- Speed and altitude patterns
- On-ground percentage

### 3. **dim_aircraft_utilization**
Per-aircraft daily utilization:
- Total flight time
- Number of flights
- Distance covered
- Operational efficiency

### 4. **dim_airspace_heatmap**
Spatial and temporal traffic analysis:
- 0.5Â° x 0.5Â° geographic grid
- Hourly traffic patterns
- Average altitude per cell
- Flight count distribution

### 5. **raw_telemetry**
Sampled raw data points (up to 1M records):
- Individual telemetry records
- Full flight state data
- Enriched with airline/route information

## ğŸš¦ Quick Start

### Prerequisites
- Docker & Docker Compose v2.0+
- 8GB+ RAM recommended (16GB optimal)
- 20GB free disk space
- OpenSky API credentials (optional, for higher rate limits)

### 1. Clone & Configure
3-5 minutes for all services to initialize. The first startup will:
- Download PostgreSQL JDBC drivers
- Initialize Airflow database
- Create MinIO buckets (aviation-bronze, aviation-silver, aviation-gold)
- Start Spark streaming with auto-restart wrapper

**Check Service Health:**
```bash
docker ps --format "table {{.Names}}\t{{.Status}}"
```

All containers should show "Up" status
```bash
git clone https://github.com/sairam030/Aviation_Analytics.git
cd Aviation_Analytics
```

### 2. Download Historical Data (Optional)

Download OpenSky historical flight data for batch processing:

```bash
# Create data directory
mkdir -p /media/D/data/aviation_data/states

# Download from OpenSky (requires free account)
# Visit: https://opensky-network.org/datasets/states/
# Download parquet files and place in the states folder
```

**Data Source:** [OpenSky Network Datasets](https://opensky-network.org/datasets/states/)

> **Note:** The batch pipeline requires historical parquet files. Without them, only the real-time speed layer will work.

### 3. Set OpenSky Credentials (Optional)

Edit `src/speed/config.py`:
```python
OPENSKY_CLIENT_ID = "your-client-id"
OPENSKY_CLIENT_SECRET = "your-client-secret"
```

Get credentials at: [OpenSky Account](https://opensky-network.org/my-opensky/account)

### 4. Start Services

```bash
docker compose up -d
```

**Wait ~3-5 minutes for first startup.** The following happens automatically:

âœ… **All driver Jars** - Downloaded during image build  
âœ… **Airflow database** - Initialized automatically  
âœ… **MinIO buckets** - Created (aviation-bronze, aviation-silver, aviation-gold)  
âœ… **Spark streaming** - Auto-starts with restart wrapper  

**No manual intervention required!** All initialization is automated.
Pipelines

**In Airflow UI (http://localhost:8080):**

1. ğŸ“ Project Structure

```
aviation_dataPipeline/
â”œâ”€â”€ dags/                                    # Airflow DAGs
â”‚   â”œâ”€â”€ aviation_states_pipeline.py         # Batch: Bronze â†’ Silver ETL
â”‚   â”œâ”€â”€ aviation_flight_mapping_pipeline.py # Batch: Flight enrichment
â”‚   â”œâ”€â”€ speed_layer_silver_ingestion.py     # Speed: Hourly persistence
â”‚   â””â”€â”€ serving_layer_postgres_load.py      # Serving: Analytics tables
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ batch/                               # Batch processing
â”‚   â”‚   â”œâ”€â”€ bronze.py                        # Raw data ingestion
â”‚   â”‚   â”œâ”€â”€ extract_india_flights.py         # India-specific extraction
â”‚   â”‚   â”œâ”€â”€ enrich.py                        # Data enrichment
â”‚   â”‚   â””â”€â”€ config.py                        # Batch configuration
â”‚   â”œâ”€â”€ speed/                               # Real-time processing
â”‚   â”‚   â”œâ”€â”€ kafka_producer.py                # OpenSky â†’ Kafka
â”‚   â”‚   â”œâ”€â”€ spark_streaming.py               # Spark structured streaming
â”‚   â”‚   â”œâ”€â”€ enrichment.py                    # Real-time enrichment
â”‚   â”‚   â””â”€â”€ accumulator_state.py             # State management
â”‚   â”œâ”€â”€ serving/                             # Analytics layer
â”‚   â”‚   â””â”€â”€ analytics_loader.py              # PostgreSQL analytics tables
â”‚   â”œâ”€â”€ webapp/                              # Flight tracker
â”‚   â”‚   â”œâ”€â”€ server.py                        # FastAPI server
â”‚   â”‚   â”œâ”€â”€ kafka_consumer.py                # Kafka consumer
â”‚   â”‚   â””â”€â”€ static/                          # Web UI (HTML/JS/CSS)
â”‚   â””â”€â”€ utils/                               # Shared utilities
â”‚       â”œâ”€â”€ spark_utils.py                   # Spark session management
â”‚       â”œâ”€â”€ metadata_loader.py               # Reference data
â”‚       â””â”€â”€ metrics_utils.py                 # Pipeline metrics & logging
â”œâ”€â”€ scripts/                                 # Operational scripts
â”‚   â”œâ”€â”€ spark_master_entrypoint.sh           # Master startup + wrapper
â”‚   â”œâ”€â”€ spark_streaming_wrapper.sh           # Auto-restart loop
â”‚   â””â”€â”€ start_spark_streaming.sh             # Streaming job launcher
â”œâ”€â”€ docker-compose.yml                       # 15-service orchestration
â”œâ”€â”€ Dockerfile                               # Spark + Python image
â””â”€â”€ README.md                                # This file
```

## ğŸ”„ Data Flow

### Batch Layer (Historical Processing)
```
Parquet Files â†’ Bronze (MinIO) â†’ Spark ETL â†’ Silver (MinIO) â†’ Gold (MinIO) â†’ PostgreSQL
```
- *ğŸ“ˆ Monitoring & Logs
### Comprehensive Pipeline Metrics

Each DAG automatically generates detailed metrics at completion:

```
ğŸ“Š PIPELINE - COMPREHENSIVE METRICS REPORT
================================================================================
ğŸ”„ DAG RUN INFORMATION
  DAG ID:           analytics_serving_layer
  Run ID:           manual__2026-01-04T16:42:34+00:00
  Execution Date:   2026-01-04 16:42:34
  Duration:         245.67s (4.09m)

ğŸ“‹ TASK EXECUTION METRICS
  âœ“ create_analytics_database        |  12.34s | success
  âœ“ merge_to_gold_bucket              | 156.78s | success
  âœ“ create_raw_telemetry              |  34.56s | success
  âœ“ create_fact_flight_history        |  23.45s | success
  
  Total Task Time:     227.13s (3.79m)
  Successful Tasks:    7/7

ğŸ’¾ DATA LAYER STATISTICS
  ğŸ¥ˆ Silver Layer (Source): aviation-silver
    Files:       1,234
    Total Size:  456.78 MB
    
  ğŸ¥‡ Gold Layer (Master): aviation-gold
    Files:       789
    Total Size:  234.56 MB

ğŸ“ˆ DATA PROCESSING METRICS
  Task: merge_to_gold_bucket
    â€¢ gold_records:               2,370,307

âš¡ PERFORMANCE SUMMARY
  Pipeline Efficiency:  92.5% (task time / wall clock time)
  Avg Task Duration:    32.45s

ğŸ¥ SYSTEM HEALTH CHECK
  MinIO Storage:    âœ… Healthy (3 buckets)
  Spark Cluster:    âœ… Healthy
  PostgreSQL:       âœ… Healthy

âœ… PIPELINE EXECUTION COMPLETE
```

### Enhanced Task Logging

All processing tasks include detailed logging with timestamps:

```
  [12:34:56] âš™ï¸ Loading batch layer data...
  [12:35:23] âœ… Batch: 2,370,307 records
  [12:35:24] âš™ï¸ Loading speed layer data...
  [12:35:45] âœ… Speed: 156,789 records
  [12:35:46] âš™ï¸ Writing to Gold bucket...
  [12:36:12] âœ… Gold master created: 2,527,096 records
```

### Application Logs
```bash
# All services
docker compose logs -f

# Specific service
docker logs -f spark-master
docker logs -f flight-tracker
docker logs -f airflow-scheduler
```

### Metrics & Dashboards
- **Spark UI**: http://localhost:8081 - Job metrics, executors, stages
- **Kafka UI**: http://localhost:8084 - Topics, consumers, messages
- **Airflow**: http://localhost:8080 - DAG status, task logs, execution metrics
- **MinIO**: http://localhost:9001 - Storage usage, bucket stats

### Pipeline Execution Tracking

Each DAG run provides:
- **Task-level metrics**: Execution time per task
- **Data statistics**: Record counts, file sizes, storage utilization
- **System health**: MinIO, Spark, PostgreSQL status checks
- **Performance metrics**: Throughput, efficiency, average processing time
- **Error tracking**: Failed task identification and retry status

View metrics in Airflow task logs or the final `show_pipeline_metrics` task.

### Health Checks
```bash
# All containers status
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# Specific service health
docker compose ps spark-master
docker compose ps kafka

# Resource usage
docker stats --no-stream
```

## ğŸ›‘ Stopping Services

### Graceful Shutdown
```bash
docker compose down
```

### Full Cleanup (including data volumes)
```bash
docker compose down -v

# This removes:
# - All containers
# - MinIO data (Bronze/Silver/Gold)
# - PostgreSQL data
# - Kafka topics
# - Airflow metadata
```

### Restart Single Service
```bash
docker compose restart spark-master
docker compose restart flight-tracker
```



## ğŸ“ License

MIT

## ğŸ”— Resources

- [OpenSky Network API](https://openskynetwork.github.io/opensky-api/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Kafka Documentation](https://kafka.apache.org/documentation/)

## ğŸ“§ Support

For issues and questions:
1. Check [Troubleshooting](#-troubleshooting) section
2. Review logs: `docker compose logs -f`
3. Verify service health: `docker ps`
4. Check Airflow task logs in UI

---

**Built  using Lambda Architecture***Spark Streaming**: Structured streaming with auto-restart
- **Flight Tracker**: Consumes enriched data, streams to WebSocket clients
- **Persistence**: Hourly DAG saves enriched data to MinIO Silver

### Serving Layer (Analytics)
```
Silver (Batch + Speed) â†’ Gold (Merged) â†’ Spark Aggregations â†’ PostgreSQL Tables â†’ Metabase
```
- **Merge Strategy**: Full load (first run) or incremental (subsequent runs)
- **5 Analytics Tables**: See Analytics Tables section above
- **Schedule**: Every 6 hours via Airflow DAG
- **Query Layer**: Metabase dashboards connect to PostgreSQL

## ğŸ› Troubleshooting

### Spark Streaming Not Running
```bash
# Check Spark master logs
docker logs spark-master | tail -50

# Should see: "Starting Spark streaming wrapper" and streaming app ID
# Visit http://localhost:8081 - should show active application
```

### Flight Tracker Shows No Data
```bash
# Check Kafka consumer connection
docker logs flight-tracker | grep -E "Consumer|Kafka"

# If "NoBrokersAvailable" error, restart container
docker compose restart flight-tracker

# Verify Kafka has data
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic aviation-enriched-states \
  --max-messages 1
```

### PostgreSQL Tables Empty
```bash
# Check if DAG ran successfully
docker logs airflow-scheduler | grep serving_layer

# Manually trigger analytics load
# In Airflow UI: serving_layer_postgres_load with load_batch_data=True

# Verify tables exist
docker exec postgres psql -U airflow -d analytics -c "\dt"
```

### MinIO Buckets Missing
```bash
# Recreate buckets
docker exec minio-create-buckets sh -c '
  mc alias set myminio http://minio:9000 minioadmin minioadmin
  mc mb myminio/aviation-bronze myminio/aviation-silver myminio/aviation-gold
'
```

### Out of Memory Errors
- Increase Docker memory allocation (recommended: 8GB minimum)
- Reduce Spark worker memory in [docker-compose.yml](docker-compose.yml)
- Check with: `docker stats`

## ğŸ”§ Configuration

### Spark Streaming Auto-Restart
The Spark streaming job automatically restarts if it fails:
- **Wrapper Script**: [scripts/spark_streaming_wrapper.sh](scripts/spark_streaming_wrapper.sh)
- **Restart Delay**: 30s after graceful exit, 60s after error
- **Logs**: `docker logs spark-master`

### Kafka Topics Configuration
- **Retention**: 7 days
- **Partitions**: 1 (increase for higher throughput)
- **Replication**: 1 (single broker)

### Analytics Update Frequency
- **Serving Layer DAG**: Every 6 hours (`0 */6 * * *`)
- **Speed Layer Ingestion**: Every hour
- **Real-time Updates**: 5-second intervals

### OpenSky API Rate Limits
- **Anonymous**: 100 requests/day, ~400 credits/day
- **Authenticated**: 4,000 requests/day, 4,000 credits/day
- **Current Setup**: Uses mock data when rate-limitedrt loop
â”‚   â””â”€â”€ start_spark_streaming.sh             # Streaming job launcher
â”œâ”€â”€ docker-compose.yml                       # 15-service orchestration
â”œâ”€â”€ Dockerfile                               # Spark + Python image
â””â”€â”€ README.md                                # This  streaming auto-starts on container launch

### 7. Verify Data Flow

**Check Kafka messages:**
```bash
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic aviation-enriched-states \
  --max-messages 5
```

**Check Spark streaming:**
```bash
docker logs spark-master | grep "Streaming"
```
Visit: http://localhost:8081 (should show active application)

**Check PostgreSQL tables:**
```bash
docker exec postgres psql -U airflow -d analytics -c "\dt"
```

**Check Flight Tracker:**
Visit: http://localhost:8050 (should show live flights on map)
| Application | URL | Credentials |
|-------------|-----|-------------|
| Airflow | http://localhost:8080 | admin / admin |
| Flight Tracker | http://localhost:8050 | - |
| MinIO Console | http://localhost:9001 | minioadmin / minioadmin |
| Kafka UI | http://localhost:8084 | - |
| Metabase | http://localhost:3000 | Setup on first visit |

### 6. Trigger Batch Pipeline

In Airflow UI, enable and trigger `aviation_states_pipeline` DAG.

## Project Structure

```
â”œâ”€â”€ dags/                          # Airflow DAGs
â”‚   â”œâ”€â”€ aviation_states_pipeline.py    # Batch ETL (Bronze â†’ Silver)
â”‚   â”œâ”€â”€ speed_layer_silver_ingestion.py # Speed layer hourly persistence
â”‚   â””â”€â”€ serving_layer_postgres_load.py  # Load to PostgreSQL
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ batch/                     # Batch layer code
â”‚   â”œâ”€â”€ speed/                     # Speed layer (Kafka, enrichment)
â”‚   â”œâ”€â”€ serving/                   # PostgreSQL loader
â”‚   â””â”€â”€ webapp/                    # Flight tracker web app
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ Dockerfile
```

## Data Flow

1. **Batch Layer**: Historical data â†’ Spark â†’ MinIO Silver
2. **Speed Layer**: OpenSky API â†’ Kafka â†’ Enrichment â†’ WebSocket + MinIO Silver
3. **Serving Layer**: Silver data â†’ PostgreSQL â†’ Metabase

## Stop Services

```bash
docker compose down
```

To remove all data:
```bash
docker compose down -v
```

## License

MIT
